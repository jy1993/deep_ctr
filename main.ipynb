{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 17, 30601, 34822, 36055, 36165, 36178, 36197, 36216, 36237, 36242, 36252, 36258, 36271, 36292, 38590, 38614, 38636, 38661, 38722, 41831] 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FNN(\n",
       "  (embedding): ModuleList(\n",
       "    (0): Linear(in_features=17, out_features=30)\n",
       "    (1): Linear(in_features=30584, out_features=30)\n",
       "    (2): Linear(in_features=4221, out_features=30)\n",
       "    (3): Linear(in_features=1233, out_features=30)\n",
       "    (4): Linear(in_features=110, out_features=30)\n",
       "    (5): Linear(in_features=13, out_features=30)\n",
       "    (6): Linear(in_features=19, out_features=30)\n",
       "    (7): Linear(in_features=19, out_features=30)\n",
       "    (8): Linear(in_features=21, out_features=30)\n",
       "    (9): Linear(in_features=5, out_features=30)\n",
       "    (10): Linear(in_features=10, out_features=30)\n",
       "    (11): Linear(in_features=6, out_features=30)\n",
       "    (12): Linear(in_features=13, out_features=30)\n",
       "    (13): Linear(in_features=21, out_features=30)\n",
       "    (14): Linear(in_features=2298, out_features=30)\n",
       "    (15): Linear(in_features=24, out_features=30)\n",
       "    (16): Linear(in_features=22, out_features=30)\n",
       "    (17): Linear(in_features=25, out_features=30)\n",
       "    (18): Linear(in_features=61, out_features=30)\n",
       "    (19): Linear(in_features=3109, out_features=30)\n",
       "  )\n",
       "  (fc1): Linear(in_features=600, out_features=200)\n",
       "  (fc2): Linear(in_features=200, out_features=200)\n",
       "  (fc3): Linear(in_features=200, out_features=1)\n",
       "  (batchnorm1): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (batchnorm2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True)\n",
       "  (dropout): Dropout(p=0.5, inplace)\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import deepfm\n",
    "model = deepfm.FNN('./data/feature_index')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "\n",
       "Columns 0 to 9 \n",
       "-0.1375 -0.0682 -0.0017  0.0756 -0.1030 -0.1669 -0.1221  0.2188  0.0895  0.2326\n",
       " 0.2064 -0.1019  0.0759 -0.0823 -0.0722 -0.1208  0.2418  0.0907  0.0444 -0.0391\n",
       " 0.0177  0.1369  0.1943  0.0671 -0.1337 -0.0054 -0.0668  0.1951 -0.0500  0.0244\n",
       "-0.1834  0.0104 -0.0870 -0.1095  0.1045  0.1892 -0.0354 -0.1732  0.1758  0.2069\n",
       "-0.1504  0.1695 -0.0703 -0.2206  0.2076  0.0971  0.1018 -0.1559 -0.1081 -0.2209\n",
       " 0.1515  0.0648 -0.1240  0.1935  0.0010 -0.1623  0.0837  0.1484  0.2160 -0.1378\n",
       " 0.1682  0.0837 -0.0203  0.1227  0.1069 -0.0141  0.0874 -0.2048 -0.0478  0.0174\n",
       " 0.1759  0.1616 -0.1096  0.1756 -0.0954 -0.1427  0.0075  0.0173 -0.0895  0.1105\n",
       "-0.1189 -0.0775  0.0755 -0.1281  0.0208 -0.0058  0.1536 -0.0046 -0.1953 -0.1300\n",
       " 0.2183  0.1966  0.2125  0.0286  0.0760  0.2356 -0.0627  0.1575  0.0835  0.1981\n",
       " 0.0541 -0.2374  0.1558 -0.0003 -0.1045  0.0322 -0.1757 -0.0512  0.2168 -0.0265\n",
       "-0.2009 -0.1570 -0.1383  0.1215  0.1049 -0.0538  0.2183  0.0777  0.2057 -0.0360\n",
       "-0.1105 -0.1799 -0.0731 -0.1943 -0.0328  0.2177  0.1001  0.0358  0.2225 -0.1435\n",
       " 0.0308  0.1277 -0.2387 -0.0747 -0.0157 -0.0732 -0.2259 -0.1663  0.2173  0.0449\n",
       "-0.1112  0.2397  0.0350 -0.2241  0.1289  0.0271  0.2374  0.0122 -0.1590 -0.2067\n",
       " 0.0311  0.2321 -0.0935  0.0565 -0.1358 -0.1780  0.0662  0.1110 -0.1110  0.0482\n",
       " 0.0760  0.0402 -0.2417 -0.2315 -0.2220  0.2267 -0.0876 -0.2239 -0.2069  0.2258\n",
       "-0.2132  0.0269  0.1785 -0.1187  0.1471 -0.0164  0.1541 -0.1038 -0.0904  0.2403\n",
       "-0.2049 -0.1087  0.2016 -0.1560 -0.0654 -0.1098  0.0011  0.0825 -0.1175 -0.0794\n",
       "-0.0053 -0.0776  0.0347  0.1372  0.1466  0.2406  0.0521 -0.1884  0.0133 -0.0086\n",
       " 0.2285 -0.1730 -0.2408  0.0703  0.2315  0.1562  0.2382  0.1213 -0.1980 -0.0309\n",
       "-0.0950  0.2046 -0.1333 -0.0491 -0.0326  0.1289  0.2026  0.2257 -0.1833 -0.0887\n",
       " 0.0846  0.1305  0.1987  0.0040 -0.2366  0.0099 -0.2330  0.0578  0.0762 -0.1088\n",
       " 0.1513  0.2141 -0.1803  0.1615  0.0635 -0.1713  0.1487  0.1554 -0.0539  0.1510\n",
       "-0.1636 -0.1095  0.1123 -0.0189  0.0718  0.0551  0.0812  0.0457 -0.0198  0.1883\n",
       " 0.0927 -0.1782 -0.1245  0.1319  0.0237  0.1099 -0.1580  0.1672 -0.1278 -0.1453\n",
       "-0.2267 -0.1536 -0.0819 -0.1499  0.0065 -0.0986 -0.0051  0.1602 -0.1661  0.0485\n",
       "-0.0100  0.0816  0.1783 -0.2411  0.0185 -0.0729  0.0117  0.1811 -0.1962  0.1869\n",
       "-0.0453  0.1691  0.0574  0.1565  0.0246  0.1980  0.1398 -0.1627 -0.2420 -0.1214\n",
       "-0.0696  0.1406 -0.0545  0.0188  0.0781  0.1389 -0.0675  0.1747 -0.0149 -0.0193\n",
       "\n",
       "Columns 10 to 16 \n",
       "-0.1069  0.1352 -0.2135  0.2256 -0.1552  0.1449 -0.0843\n",
       "-0.0197 -0.1431 -0.0374 -0.0692 -0.0893 -0.0379  0.0020\n",
       "-0.1450  0.2392  0.1515  0.1446 -0.2383 -0.1578 -0.1912\n",
       "-0.1036  0.2358  0.1726 -0.0377 -0.2187  0.1407 -0.1434\n",
       "-0.0117 -0.1252  0.1039 -0.2383  0.0796 -0.0145 -0.1080\n",
       "-0.1224  0.2095  0.1113  0.2359  0.0193  0.1423 -0.1547\n",
       " 0.1294  0.0040  0.1909  0.2168 -0.0790  0.1591 -0.0175\n",
       " 0.0429  0.0670 -0.2017 -0.1645 -0.1916  0.1211  0.2310\n",
       "-0.2024 -0.0094  0.1655 -0.1846  0.0365  0.2055 -0.0462\n",
       " 0.0015 -0.0237  0.1500 -0.0504  0.1075  0.0354 -0.1769\n",
       "-0.1181 -0.1614 -0.0782 -0.1587 -0.0297 -0.2350  0.1709\n",
       "-0.2371  0.2206 -0.2335 -0.0659  0.1517 -0.1064 -0.1671\n",
       "-0.0763  0.0582 -0.1356  0.0989  0.2308  0.0717  0.0089\n",
       " 0.0232  0.0971  0.1475  0.0956  0.0937  0.2295 -0.1297\n",
       " 0.2206  0.2113  0.0976 -0.0691  0.0133 -0.2105 -0.1925\n",
       "-0.0459  0.0695  0.1979  0.2124 -0.1392 -0.0172  0.1161\n",
       " 0.1072 -0.2291 -0.0198  0.1717 -0.2361  0.0570  0.2182\n",
       " 0.0531  0.1320  0.0251  0.0900  0.2278  0.1892  0.1550\n",
       " 0.0906 -0.0915 -0.0843 -0.0455  0.0827 -0.1249 -0.0777\n",
       "-0.0795 -0.1839 -0.0024  0.0401  0.0655 -0.0129 -0.0578\n",
       "-0.0080 -0.0369  0.0388 -0.1358  0.1935  0.0639  0.1510\n",
       "-0.0565 -0.1860 -0.1707  0.0870  0.0747 -0.0616 -0.1896\n",
       "-0.0149  0.1492  0.1243 -0.0989 -0.1613  0.0296  0.1426\n",
       "-0.2225 -0.0266  0.1177  0.0885  0.1778 -0.0505 -0.0699\n",
       "-0.0185  0.2193 -0.0389  0.1383  0.0394 -0.1657 -0.2187\n",
       " 0.1115  0.1052  0.0026  0.1927 -0.0054  0.0817  0.1624\n",
       " 0.1796 -0.0744  0.0621 -0.0988  0.2011  0.1699 -0.0488\n",
       " 0.1759 -0.2331 -0.1790  0.0312 -0.2354 -0.1604  0.0975\n",
       "-0.0315  0.1244  0.1344  0.1590 -0.0887  0.1863 -0.0270\n",
       " 0.2110 -0.0953  0.0021 -0.0512 -0.0280 -0.0604  0.2297\n",
       "[torch.FloatTensor of size 30x17]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embedding[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "1.00000e-02 *\n",
       " -2.5119\n",
       "  2.4778\n",
       "  2.4308\n",
       " -3.1049\n",
       "  0.5495\n",
       " -0.7660\n",
       "  0.1843\n",
       "  1.8139\n",
       "  3.0623\n",
       " -1.9388\n",
       " -1.0836\n",
       "  3.7071\n",
       " -0.5961\n",
       " -1.6345\n",
       "  3.2512\n",
       "  0.4867\n",
       "  3.2224\n",
       "  3.3691\n",
       " -3.6642\n",
       " -0.0788\n",
       "  1.8777\n",
       "  0.3182\n",
       " -0.8052\n",
       " -0.0028\n",
       "  1.2253\n",
       " -3.0313\n",
       " -3.2248\n",
       " -1.3666\n",
       "  1.6438\n",
       " -2.7471\n",
       "  0.8079\n",
       " -2.3597\n",
       " -3.3681\n",
       " -2.5337\n",
       "  2.7988\n",
       "  0.4958\n",
       "  3.0478\n",
       "  2.3265\n",
       "  1.0769\n",
       "  2.8858\n",
       " -1.1764\n",
       "  0.1039\n",
       " -0.3412\n",
       "  1.0936\n",
       " -0.6902\n",
       "  0.6210\n",
       " -3.8997\n",
       " -2.5635\n",
       "  2.5156\n",
       "  0.3354\n",
       " -2.3978\n",
       " -0.5913\n",
       " -3.5471\n",
       " -2.0789\n",
       "  0.3503\n",
       " -0.6047\n",
       " -0.1278\n",
       "  3.5377\n",
       "  1.7884\n",
       " -0.1099\n",
       "  3.8222\n",
       " -2.7042\n",
       " -0.1615\n",
       "  3.6040\n",
       " -0.2664\n",
       " -2.0133\n",
       " -1.3341\n",
       " -2.0646\n",
       "  3.6594\n",
       "  0.3806\n",
       " -4.0288\n",
       "  3.5165\n",
       "  4.0656\n",
       " -4.0728\n",
       " -1.5288\n",
       "  0.5357\n",
       " -3.0836\n",
       "  0.9480\n",
       " -3.2000\n",
       "  1.0034\n",
       " -1.9197\n",
       " -3.0109\n",
       "  0.5045\n",
       "  3.1492\n",
       "  1.0592\n",
       "  2.2455\n",
       " -0.2032\n",
       "  2.6844\n",
       "  3.8540\n",
       "  3.6929\n",
       " -0.1758\n",
       " -2.4145\n",
       " -3.9576\n",
       "  2.9575\n",
       "  3.7757\n",
       " -0.1972\n",
       " -0.4005\n",
       "  3.7151\n",
       "  1.7951\n",
       " -4.0357\n",
       " -2.8356\n",
       " -3.4597\n",
       " -0.5760\n",
       "  2.5179\n",
       "  2.6467\n",
       "  1.6027\n",
       " -1.9333\n",
       " -3.4493\n",
       " -1.5182\n",
       " -3.8004\n",
       " -3.4957\n",
       "  2.5990\n",
       " -1.6677\n",
       "  0.9127\n",
       "  2.0354\n",
       "  3.9093\n",
       "  2.6958\n",
       "  0.2777\n",
       "  1.3367\n",
       "  0.9266\n",
       " -1.0226\n",
       " -3.5181\n",
       " -3.3888\n",
       " -0.9211\n",
       " -1.1978\n",
       "  3.1684\n",
       "  1.3702\n",
       "  1.6478\n",
       " -1.9814\n",
       " -1.0142\n",
       " -0.4195\n",
       "  2.5691\n",
       "  0.3710\n",
       " -3.1975\n",
       " -3.7591\n",
       "  0.9859\n",
       "  2.4791\n",
       " -1.4046\n",
       " -3.9092\n",
       "  3.2146\n",
       "  1.1814\n",
       " -0.8035\n",
       "  0.5606\n",
       "  1.6656\n",
       "  0.3183\n",
       "  2.9710\n",
       "  2.6359\n",
       " -0.7019\n",
       "  3.2920\n",
       " -0.9498\n",
       " -3.6511\n",
       "  4.0266\n",
       "  0.7218\n",
       " -2.6478\n",
       "  2.6760\n",
       " -0.1773\n",
       "  3.6448\n",
       " -1.2680\n",
       " -2.8838\n",
       "  3.4808\n",
       " -3.1081\n",
       " -2.5874\n",
       " -3.6103\n",
       " -0.2305\n",
       " -3.6365\n",
       " -3.4797\n",
       " -3.1257\n",
       " -1.6288\n",
       " -1.5933\n",
       "  0.0598\n",
       " -1.9829\n",
       "  0.2496\n",
       " -1.8316\n",
       " -0.3587\n",
       " -1.9489\n",
       "  1.9096\n",
       "  2.2073\n",
       " -0.9421\n",
       "  2.4469\n",
       " -2.4895\n",
       " -2.4282\n",
       "  1.9432\n",
       "  1.5476\n",
       " -2.3146\n",
       " -1.9849\n",
       " -2.3519\n",
       " -0.8194\n",
       "  2.8394\n",
       "  1.4392\n",
       "  0.8784\n",
       " -2.7842\n",
       " -0.8886\n",
       "  3.5011\n",
       "  0.5802\n",
       "  3.7805\n",
       " -1.0538\n",
       " -2.6252\n",
       "  2.5466\n",
       "  2.8126\n",
       " -0.5946\n",
       "[torch.FloatTensor of size 200]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fc2.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ali_transform import get_data\n",
    "ali = get_data.Ali('./data/train.csv', 'val', './data/feature_index')\n",
    "from torch.utils.data import DataLoader\n",
    "val_loader = DataLoader(dataset=ali, batch_size=100)\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 600])\n",
      "torch.Size([100, 200])\n",
      "Variable containing:\n",
      " 0.5300\n",
      " 0.4030\n",
      " 0.3291\n",
      " 0.4481\n",
      " 0.4008\n",
      " 0.4680\n",
      " 0.3753\n",
      " 0.4114\n",
      " 0.5861\n",
      " 0.3571\n",
      " 0.5203\n",
      " 0.4577\n",
      " 0.3573\n",
      " 0.3932\n",
      " 0.4758\n",
      " 0.5605\n",
      " 0.5668\n",
      " 0.4459\n",
      " 0.4398\n",
      " 0.4345\n",
      " 0.5226\n",
      " 0.5001\n",
      " 0.4887\n",
      " 0.6081\n",
      " 0.4958\n",
      " 0.5354\n",
      " 0.5342\n",
      " 0.4727\n",
      " 0.5034\n",
      " 0.4997\n",
      " 0.5149\n",
      " 0.4976\n",
      " 0.2908\n",
      " 0.4334\n",
      " 0.4902\n",
      " 0.4795\n",
      " 0.4549\n",
      " 0.4152\n",
      " 0.4349\n",
      " 0.3265\n",
      " 0.2729\n",
      " 0.5003\n",
      " 0.4029\n",
      " 0.4781\n",
      " 0.4695\n",
      " 0.4632\n",
      " 0.4222\n",
      " 0.4886\n",
      " 0.4769\n",
      " 0.4366\n",
      " 0.5676\n",
      " 0.4787\n",
      " 0.4789\n",
      " 0.4494\n",
      " 0.4000\n",
      " 0.4853\n",
      " 0.4291\n",
      " 0.4887\n",
      " 0.3960\n",
      " 0.4791\n",
      " 0.4378\n",
      " 0.5038\n",
      " 0.4891\n",
      " 0.3956\n",
      " 0.4828\n",
      " 0.6356\n",
      " 0.5579\n",
      " 0.4904\n",
      " 0.4846\n",
      " 0.4619\n",
      " 0.4384\n",
      " 0.6177\n",
      " 0.3975\n",
      " 0.5291\n",
      " 0.5341\n",
      " 0.4743\n",
      " 0.5049\n",
      " 0.5572\n",
      " 0.6134\n",
      " 0.4540\n",
      " 0.4015\n",
      " 0.4671\n",
      " 0.4315\n",
      " 0.4209\n",
      " 0.4404\n",
      " 0.4028\n",
      " 0.4311\n",
      " 0.4739\n",
      " 0.5828\n",
      " 0.5874\n",
      " 0.4867\n",
      " 0.4229\n",
      " 0.4765\n",
      " 0.4629\n",
      " 0.4755\n",
      " 0.5209\n",
      " 0.4667\n",
      " 0.4762\n",
      " 0.4840\n",
      " 0.4508\n",
      "[torch.FloatTensor of size 100]\n",
      "\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 1\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 100]\n",
      "\n",
      "Variable containing:\n",
      " 0.6474\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c2442e769243>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBCELoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[1;32mfor\u001b[0m \u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mii\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mc_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# same-process loading\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\yanji\\Documents\\GitHub\\al_ctr\\ali_transform\\get_data.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0mmax_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0mcat_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mterms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m                 \u001b[0mall_f_index\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mcat_f\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcat_features\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "criterion = torch.nn.BCELoss()\n",
    "for ii, (c_data, labels) in enumerate(val_loader):\n",
    "    if ii == 0:\n",
    "        c_data = Variable(c_data)\n",
    "        labels = Variable(labels).float()\n",
    "        pred = model(c_data)\n",
    "        print(pred)\n",
    "        print(labels)\n",
    "        loss = criterion(pred, labels)\n",
    "        print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "a = torch.ones([1,2])\n",
    "b = torch.ones([1,1])\n",
    "b = torch.ones([1,3])\n",
    "c = torch.cat([a,b,c],1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
